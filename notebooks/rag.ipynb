{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b40bc3-5ba6-4b2c-893c-950002c43295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import hashlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ed953f-e8a0-4660-8915-db0a0c5141dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_html(html_content):\n",
    "#     soup = BeautifulSoup(html_content, 'html.parser')\n",
    "#     return soup.get_text(separator=' ', strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7501ec-9ba5-4a4a-8a45-88463b93c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     # Remove extra whitespace\n",
    "#     text = re.sub(r'\\s+', ' ', text)\n",
    "#     # Remove special characters\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)\n",
    "#     return text.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66f52a-ad8a-4d36-92e3-6d2ae98be669",
   "metadata": {},
   "source": [
    "# Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66504ea2-ced3-40ad-be19-0ad753f73aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_document_id(doc):\n",
    "    combined = f\"{doc['title']}-{doc['url']}-{doc['html'][:50]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    return hash_object.hexdigest()[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e0a9c0-683b-4b62-aff7-2fab7e0e3d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chunk_text(text, chunk_size=1000):\n",
    "#     return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "\n",
    "def chunk_text(text, chunk_size=500, overlap_size=20):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(words)\n",
    "    while start < text_length:\n",
    "        end = start + chunk_size\n",
    "        chunk = \" \".join(words[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_size - overlap_size\n",
    "        if end >= text_length:\n",
    "            break\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce590751-d93a-4003-be20-1982c46c02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_html_content(html):\n",
    "#     # Remove the common header/navigation content\n",
    "#     cleaned_text = re.sub(r'^.*?Powered by GitBook', '', html, flags=re.DOTALL)\n",
    "    \n",
    "#     # Remove any remaining navigation-like content at the end\n",
    "#     cleaned_text = re.sub(r'Previous.*?Last updated.*?$', '', cleaned_text, flags=re.DOTALL)\n",
    "    \n",
    "#     # Remove extra whitespace and newlines\n",
    "#     cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "#     return cleaned_text\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_html_content(html):\n",
    "    # Remove the common header/navigation content\n",
    "    cleaned_text = re.sub(r'^.*?Powered by GitBook', '', html, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'^.*?Terms of Service', '', html, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'^.*?Disclaimer', '', html, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'Previous.*?Last updated.*?$', '', cleaned_text, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'\\*\\*', '', cleaned_text) \n",
    "    cleaned_text = re.sub(r'[^\\x00-\\x7F]+', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'@\\w+', '', cleaned_text) \n",
    "    cleaned_text = re.sub(r'<[^>]+>', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\\\n', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab04af9-ee1d-4ad2-9d86-5c1b8a6e31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(documents):\n",
    "    processed_docs = []\n",
    "    irrelevant_titles = ['Terms of Use', 'Contact us', 'Disclaimer', 'Terms of Service']\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Skip irrelevant pages\n",
    "        if any(title.lower() in doc['title'].lower() for title in irrelevant_titles):\n",
    "            continue\n",
    "        \n",
    "        # Clean HTML content\n",
    "        text = clean_html_content(doc['html'])\n",
    "        title = clean_html_content(doc['title'])\n",
    "        # Generate document ID\n",
    "        doc_id = generate_document_id(doc)\n",
    "\n",
    "        # processed_docs.append({\n",
    "        #     'doc_id': doc_id,\n",
    "        #     'chunk_id': doc_id,  # Use doc_id as chunk_id for consistency\n",
    "        #     'text': text,\n",
    "        #     'title': doc['title'],\n",
    "        #     'url': doc['url'],\n",
    "        #     'source': doc['source']\n",
    "        # })\n",
    "        \n",
    "        # Chunk the text\n",
    "        chunks = chunk_text(text)\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_id = f\"{doc_id}_{i}\"\n",
    "            processed_docs.append({\n",
    "                'doc_id': doc_id,\n",
    "                'chunk_id': chunk_id,\n",
    "                'text': chunk,\n",
    "                'title': title,\n",
    "                'url': doc['url'],\n",
    "                'source': doc['source']\n",
    "            })\n",
    "    \n",
    "    return processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3faf5a2-034a-427e-befb-4441390a4049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directory: C:\\Users\\dimi\\Desktop\\parthenon-rag\\data\\json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9087facf7e4244b09096b8ec0f60e108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading JSON files:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 561 documents from 44 JSON files.\n",
      "Created 653 chunks from 561 documents.\n",
      "Unique sources: json/routex-1.json, json/echelonmarket-1.json, json/Movement - ──── Movement Info - 🏛┃testnet-guide [1267717617339072553].json, json/Seekers Alliance - │faqs [1114042684370321449].json, json/brkt-brings-gamblefi-1.json, json/securing-smart-contracts-a-devs-guide-part-ii-1.json, json/movewiffrens-1.json, json/Satay 2.0 - ✧ Welcome ✧ - about-us [1258261708011470900].json, json/movement-sdk-unifying-the-blockchain-universe-2-1.json, json/binance-labs-backs-movement-labs-mission-1.json, json/Seekers Alliance - bounty-board [1114081267147882556].json, json/wikiinfiniteseas2-1.json, json/henrysocial-1.json, json/satayfinance-1.json, json/BRKT - BRKT TEAM - 📋-start-here [1258738649864994836].json, json/omnibtclabs-1.json, json/stablejack-1.json, json/Satay 2.0 - ✧ Welcome ✧ - start-here [1262316226873524254].json, json/MovementCommunityProgram-1.json, json/WarpGate_Official - galxe-quest-faq [1268083648725254184].json, json/Avitus - ▬▬・Info Desk・▬▬ - 🧷・about [1232974910746263592].json, json/movementnetwork9-1.json, json/Mosaic - 💥BEGINS HERE - ✅│links-information [1268143410842304585].json, json/xebratrade-1.json, json/ParthenonWallets-1.json, json/warpgate-1.json, json/Infinite Seas - Information - version-history [1284657419594498208].json, json/nightly-1.json, json/RIZE - RIZE __ INFO - 💡︱tutorial [1248801649850454139].json, json/Stable Jack - faq [1207954817205407794].json, json/razorwallet-1.json, json/DegenHive - resources [1265306626424963072].json, json/mosaic-1.json, json/Avitus - ▬▬・Start Here・▬▬ - ⭐・roles [1272432002464743444].json, json/Seekers Alliance - │role-book [1114042659552632912].json, json/gorillamoverz-1.json, json/DegenHive - start-here [1265339209787379822].json, json/Razor DAO - faq [1172072907434885190].json, json/scaffoldmove-1.json, json/Movement - ──── Movement Info - 🏛┃testnet-news [1268276163176829019].json, json/Movement - ──── Movement Info - 🤝┃start-here [1177482116750114927].json, json/blogmovementlabs-1.json, json/Nexio - start⋅here [1260490148949262386].json, json/securing-smart-contracts-a-devs-guide-part-i-1.json\n"
     ]
    }
   ],
   "source": [
    "def load_documents(directory_path):\n",
    "    documents = []\n",
    "    json_files = glob.glob(os.path.join(directory_path, '*.json'))\n",
    "\n",
    "    for file_path in tqdm(json_files, desc=\"Loading JSON files\"):\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "        except UnicodeDecodeError:\n",
    "            with open(file_path, 'r', encoding='cp1252') as file:\n",
    "                data = json.load(file)\n",
    "        \n",
    "        if isinstance(data, list):\n",
    "            # Existing structure\n",
    "            for doc in data:\n",
    "                documents.append({\n",
    "                    'html': doc.get('html', ''),\n",
    "                    'title': doc.get('title', ''),\n",
    "                    'url': doc.get('url', ''),\n",
    "                    'source': f\"json/{os.path.basename(file_path)}\"\n",
    "                })\n",
    "        elif isinstance(data, dict) and 'messages' in data:\n",
    "            # New structure with messages/content\n",
    "            for message in data['messages']:\n",
    "                content = message.get('content', '')\n",
    "                if content:\n",
    "                    documents.append({\n",
    "                        'html': content,\n",
    "                        'title': f\"Message from {message.get('author', {}).get('name', 'Unknown')}\",\n",
    "                        'url': '',\n",
    "                        'source': f\"json/{os.path.basename(file_path)}\"\n",
    "                    })\n",
    "        else:\n",
    "            print(f\"Unsupported JSON structure in file: {file_path}\")\n",
    "    \n",
    "    return documents, json_files\n",
    "\n",
    "current_directory = os.path.abspath(os.path.join(os.getcwd(), '..', 'data', 'json'))\n",
    "\n",
    "print(f\"Using directory: {current_directory}\")\n",
    "\n",
    "# Load the JSON data\n",
    "try:\n",
    "    documents, json_files = load_documents(current_directory)\n",
    "    print(f\"Successfully loaded {len(documents)} documents from {len(json_files)} JSON files.\")\n",
    "\n",
    "    processed_documents = process_documents(documents)\n",
    "    print(f\"Created {len(processed_documents)} chunks from {len(documents)} documents.\")\n",
    "    \n",
    "    sources = set(doc['source'] for doc in documents)\n",
    "    print(f\"Unique sources: {', '.join(sources)}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the documents: {e}\")\n",
    "    processed_documents = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf1cfd-a314-4957-acfb-2b35f2f7ebde",
   "metadata": {},
   "source": [
    "**RAG flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02aaedf8-21ad-4550-b427-3ce450007a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a9fbd4-5575-4936-87b9-c345f242d886",
   "metadata": {},
   "source": [
    "**Index and search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0b75efa-e1c1-497d-b05b-a3c1b1ac4397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '1f8253bbe4fa', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'SmChPidnTz6tTnDxFHIgSQ', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n",
      "Deleted index: movement-wiki\n",
      "Created index: movement-wiki\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.exceptions import NotFoundError\n",
    "\n",
    "# Initialize Elasticsearch client\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "print(es_client.info())\n",
    "\n",
    "\n",
    "index_name = \"movement-wiki\"\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"doc_id\": {\"type\": \"keyword\"},\n",
    "            \"chunk_id\": {\"type\": \"keyword\"},\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"url\": {\"type\": \"keyword\"},\n",
    "            \"source\": {\"type\": \"keyword\"},\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# Delete existing index if it exists\n",
    "try:\n",
    "    response = es_client.indices.delete(index=index_name)\n",
    "    print(f\"Deleted index: {index_name}\")\n",
    "except NotFoundError:\n",
    "    print(f\"Index {index_name} not found, nothing to delete\")\n",
    "\n",
    "# Create new index\n",
    "es_client.indices.create(index=index_name, settings=index_settings['settings'], mappings=index_settings['mappings'])\n",
    "\n",
    "print(f\"Created index: {index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d63893d5-c905-42df-a341-16060a1f25c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimi\\.virtualenvs\\parthenon-rag-8QEwNaaS\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a1b65e-cfe2-4758-a6d9-15a2ef62f28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6253f059e72e46f8bdfbad6a05602ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing documents:   0%|          | 0/653 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 653 documents\n",
      "Index refreshed\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch.helpers import bulk\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def index_documents(documents, batch_size=500):\n",
    "    actions = []\n",
    "    for doc in tqdm(documents, desc=\"Indexing documents\"):\n",
    "        try:\n",
    "            text_vector = model.encode(doc['text']).tolist()\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding document {doc['doc_id']}: {e}\")\n",
    "            continue\n",
    "\n",
    "        action = {\n",
    "            '_op_type': 'index',\n",
    "            '_index': index_name,\n",
    "            '_source': {\n",
    "                'doc_id': doc['doc_id'],\n",
    "                'chunk_id': doc['chunk_id'],\n",
    "                'text': doc['text'],\n",
    "                'title': doc['title'],\n",
    "                'url': doc['url'],\n",
    "                'source': doc['source'],\n",
    "                'text_vector': text_vector\n",
    "            }\n",
    "        }\n",
    "        actions.append(action)\n",
    "\n",
    "        if len(actions) >= batch_size:\n",
    "            bulk(es_client, actions)\n",
    "            actions = []  # Clear actions list after bulk index\n",
    "\n",
    "    # Index remaining documents if any\n",
    "    if actions:\n",
    "        bulk(es_client, actions)\n",
    "\n",
    "    print(f\"Indexed {len(documents)} documents\")\n",
    "\n",
    "index_documents(processed_documents)\n",
    "\n",
    "# Refresh the index after all documents are indexed\n",
    "es_client.indices.refresh(index=index_name)\n",
    "print(\"Index refreshed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f055f74-cae3-4e04-8a7a-02556dc9333b",
   "metadata": {},
   "source": [
    "## Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b23f4e0-fd8d-47a2-9f99-a2849dbf7053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_search(query, size=5, source=None):\n",
    "    search_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"title\", \"text^3\"],\n",
    "                        \"type\": \"best_fields\",\n",
    "                        \"fuzziness\": \"AUTO\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"match_phrase\": {\n",
    "                        \"text\": {\n",
    "                            \"query\": query,\n",
    "                            \"boost\": 2\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    if source:\n",
    "        search_query[\"bool\"][\"filter\"] = {\n",
    "            \"term\": {\n",
    "                \"source\": source\n",
    "            }\n",
    "        }\n",
    "\n",
    "    response = es_client.search(\n",
    "        index=index_name,\n",
    "        query=search_query,\n",
    "        size=size,\n",
    "        _source=[\"doc_id\", \"chunk_id\", \"text\", \"title\", \"url\", \"source\"]\n",
    "    )\n",
    "    return [hit['_source'] for hit in response['hits']['hits']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e945ee-a31f-4bf4-8715-505f1bc52a5e",
   "metadata": {},
   "source": [
    "## Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ba9ec-f7e7-4b46-8110-b642d88ff0a6",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9980f275-7914-4075-a622-9b5afa5565dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, query, source=None):\n",
    "    query_vector = model.encode(query).tolist()\n",
    "\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": query_vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000\n",
    "    }\n",
    "\n",
    "    if source:\n",
    "        knn[\"filter\"] = {\n",
    "            \"term\": {\n",
    "                \"source\": source\n",
    "            }\n",
    "        }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"doc_id\", \"chunk_id\", \"text\", \"title\", \"url\", \"source\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "\n",
    "    # Extract and return the documents\n",
    "    return [hit['_source'] for hit in es_results['hits']['hits']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c00f62-9413-4198-9ea4-21f6d56b9051",
   "metadata": {},
   "source": [
    "### Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "042711d4-07f4-4be3-a275-3e1c6b6c0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_hybrid(query, vector, size=5):\n",
    "    knn_query = {\n",
    "        \"field\": \"text_vector\",\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": size,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5\n",
    "    }\n",
    "\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"text^3\", \"title\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5,\n",
    "                    \"fuzziness\": \"AUTO\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn_query,\n",
    "        \"query\": keyword_query,\n",
    "        \"size\": size,\n",
    "        \"_source\": [\"doc_id\", \"chunk_id\", \"text\", \"title\", \"url\", \"source\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    return [hit['_source'] for hit in es_results['hits']['hits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e0cd48e-6c2a-49ed-b7e0-76e20d4444d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query, size=5):\n",
    "    query_vector = model.encode(query).tolist()\n",
    "    return elastic_search_hybrid(query, query_vector, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30d9ce-f1d2-4866-88f7-8866d8498af5",
   "metadata": {},
   "source": [
    "## Build prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3a299b0-6e93-4e54-a823-2ae95095fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an AI-powered Assistant for Movement Labs, specializing in the Move language and the Movement Network ecosystem. \n",
    "Answer the QUESTION based strictly on the CONTEXT from the knowledge base. If the CONTEXT does not provide enough details, request more information or clarify the question. \n",
    "\n",
    "Your answer should be clear, concise, and factual. Follow these guidelines:\n",
    "- Provide a complete answer in 2-3 short paragraphs or bullet points for clarity.\n",
    "- Focus on the most relevant information.\n",
    "- If the QUESTION is unclear, ask for clarification.\n",
    "- Do not speculate or generate information not present in the CONTEXT.\n",
    "- Ensure your response is complete and not cut off mid-sentence.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "Document ID: {doc_id}\n",
    "Chunk ID: {chunk_id}\n",
    "Title: {title}\n",
    "URL: {url}\n",
    "Content: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context += entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "006dcaba-d635-474d-9c89-801c11fcfef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini', max_tokens=150):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "073bf27f-34b4-47b0-961c-608f1dee1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = 'What functions does the ContractRouter smart contract serve in relation to participant registration??'\n",
    "# size=3\n",
    "# model='gpt-4o-mini'\n",
    "# source=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "317e1c2f-24a9-4c1b-af32-4c99057ff99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform the search\n",
    "# search_results = text_search(query, 5, source)\n",
    "\n",
    "# # Debug: Print the structure of search_results\n",
    "# print(\"Structure of search_results:\")\n",
    "# print(json.dumps(search_results[0] if search_results else {}, indent=2))\n",
    "\n",
    "# # Adjust the code based on the actual structure\n",
    "# # Assuming search_results is a list of dictionaries with the document information\n",
    "\n",
    "# # Build the prompt and get the answer\n",
    "# prompt, context = build_prompt(query, search_results)\n",
    "# answer = llm(prompt, model=model, max_tokens=250)\n",
    "\n",
    "# # Print the results\n",
    "# print(f\"\\nQuery: {query}\")\n",
    "# print(f\"\\nAnswer: {answer}\")\n",
    "\n",
    "# print(\"\\nSearch results:\")\n",
    "# for doc in search_results:\n",
    "#     print(f\"Doc ID: {doc.get('doc_id', 'N/A')}\")\n",
    "#     print(f\"Chunk ID: {doc.get('chunk_id', 'N/A')}\")\n",
    "#     print(f\"Title: {doc.get('title', 'N/A')}\")\n",
    "#     print(f\"Source: {doc.get('source', 'N/A')}\")\n",
    "#     print(f\"URL: {doc.get('url', 'N/A')}\")\n",
    "#     print(f\"Text snippet: {doc.get('text', 'N/A')[:100]}...\")  # First 100 characters of the text\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "# # Print the full context used for the answer\n",
    "# print(\"\\nFull context used:\")\n",
    "# print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73e2c4c1-9f5f-4b4c-8840-05af5ab177ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62486a2e-dce6-4cd9-bd80-df844b3e92f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b63b4-179f-4cca-afc3-a75d75d7d10e",
   "metadata": {},
   "source": [
    "**Ground truth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38ab6662-1ea3-4428-88ba-9f5457ed08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_truth(documents, num_questions=3):\n",
    "    ground_truth = []\n",
    "    for doc in tqdm(documents, desc=\"Generating ground truth\"):\n",
    "        prompt = f\"\"\"\n",
    "        You are a curious user. Based on the following document, generate {num_questions} questions that can be answered using the information provided.\n",
    "        Make the questions specific to the content and avoid general questions.\n",
    "        \n",
    "        Document:\n",
    "        \n",
    "        Title: {doc['title']}\n",
    "        Content: {doc['text']}\n",
    "        Provide the output as parsable JSON without using code blocks:\n",
    "        \n",
    "        {{\"questions\": [\"question1\", \"question2\", ..., \"question{num_questions}\"]}}\n",
    "        \"\"\"\n",
    "        response = llm(prompt, model='gpt-4o-mini', max_tokens=1000)\n",
    "        try:\n",
    "            parsed_response = json.loads(response)\n",
    "            questions = parsed_response.get('questions', [])\n",
    "            for question in questions:\n",
    "                ground_truth.append({\n",
    "                    'question': question,\n",
    "                    'doc_id': doc['doc_id'],\n",
    "                    'chunk_id': doc['chunk_id']\n",
    "                })\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing response for document {doc['doc_id']}\")\n",
    "            print(\"Raw response:\", response)\n",
    "    \n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9afa4f7-26f1-4437-bd90-913d517606da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f10a9c2bb214cf6a60592a9ab47a08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating ground truth:   0%|          | 0/653 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response for document afabb682\n",
      "Raw response: {\"questions\": [\"What are the three possible outcomes when submitting batch transactions and their corresponding HTTP status codes?\", \"What is the required format for the 'sender' field in the SubmitTransactionRequest when submitting a transaction?\", \"What is the purpose of the 'expiration_timestamp_secs' field in the transaction request?\"']}\n",
      "Error parsing response for document 5717ea40\n",
      "Raw response: {\"questions\":[\"What does the useAptosAccountBalance hook return when fetching the account balance?\",\"What happens to the balance value if there is an error during the fetch operation?\",\"Which type should the balance be converted to for calculations if it exceeds Number.MAX_SAFE_INTEGER?\"asi\n",
      "Error parsing response for document c1474180\n",
      "Raw response: {\"questions\":[\"What unique benefits does xAVAX provide compared to traditional leveraged contracts?\",\"How does xAVAX enable users to gain exposure to AVAX price movements without the risks of liquidation?\",\"In what ways can xAVAX be utilized within DeFi activities?\"}]\n"
     ]
    }
   ],
   "source": [
    "# Generate ground truth\n",
    "processed_documents = process_documents(documents)\n",
    "ground_truth = generate_ground_truth(processed_documents, num_questions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7430e3c-54c4-479a-9f47-ede267c9116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(data_dir, 'ground-truth-retrieval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95f2e039-4aab-4edd-8319-13f4baadaeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth saved to 'C:\\Users\\dimi\\Desktop\\parthenon-rag\\data\\ground-truth-retrieval.csv'\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(ground_truth)\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Ground truth saved to '{csv_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690c97d-4474-473e-acdd-dc4e5060f1cb",
   "metadata": {},
   "source": [
    "**Retrieval evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd540f5-637a-4665-8bcf-765e8b98110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question    doc_id    chunk_id\n",
      "0      What type of protocol is Avitus described as?  a88e0ac9  a88e0ac9_0\n",
      "1  What unique feature does Avitus offer regardin...  a88e0ac9  a88e0ac9_0\n",
      "2       Where can users test the features of Avitus?  a88e0ac9  a88e0ac9_0\n",
      "3    What is the link to the Avitus Twitter account?  df283f30  df283f30_0\n",
      "4             Where can I find the Avitus Brand Kit?  df283f30  df283f30_0\n"
     ]
    }
   ],
   "source": [
    "df_question = pd.read_csv(csv_path)\n",
    "print(df_question.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47b28932-988e-417b-bd8d-94e40eac93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2ecaeeb-3e20-4479-bc67-b2f1012de4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What type of protocol is Avitus described as?',\n",
       " 'doc_id': 'a88e0ac9',\n",
       " 'chunk_id': 'a88e0ac9_0'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1198f850-03d6-4d95-af62-d9f53e727883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_list):\n",
    "    return sum(1 for item in relevance_list if any(item)) / len(relevance_list)\n",
    "\n",
    "def mrr(relevance_list):\n",
    "    reciprocal_ranks = []\n",
    "    for item in relevance_list:\n",
    "        try:\n",
    "            first_relevant = next(i for i, rel in enumerate(item, 1) if rel)\n",
    "            reciprocal_ranks.append(1 / first_relevant)\n",
    "        except StopIteration:\n",
    "            reciprocal_ranks.append(0)\n",
    "    return sum(reciprocal_ranks) / len(reciprocal_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51e69fc2-cda4-4e32-8868-3cfaf9f10576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ce832fb-c21d-4622-a443-4b4c07293b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_search_methods(ground_truth, search_functions):\n",
    "    results_file = 'evaluation_results.json'\n",
    "    \n",
    "    # Load existing results if available\n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file, 'r') as f:\n",
    "            results = json.load(f)\n",
    "        print(\"Loaded existing results. Continuing from where we left off.\")\n",
    "    else:\n",
    "        results = {'total_questions': len(ground_truth)}\n",
    "    \n",
    "    for name, search_function in search_functions.items():\n",
    "        if name in results:\n",
    "            print(f\"Skipping {name} as it has already been evaluated.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Starting evaluation of {name}\")\n",
    "        start_time = time.time()\n",
    "        doc_relevance = []\n",
    "        chunk_relevance = []\n",
    "        search_times = []\n",
    "        \n",
    "        try:\n",
    "            for item in tqdm(ground_truth, desc=f\"Evaluating {name}\"):\n",
    "                try:\n",
    "                    query_start_time = time.time()\n",
    "                    results_list = search_function(item['question'])\n",
    "                    query_time = time.time() - query_start_time\n",
    "                    search_times.append(query_time)\n",
    "                    \n",
    "                    doc_rel = [doc['doc_id'] == item['doc_id'] for doc in results_list]\n",
    "                    doc_relevance.append(doc_rel)\n",
    "                    \n",
    "                    chunk_rel = [doc['chunk_id'] == item['chunk_id'] for doc in results_list]\n",
    "                    chunk_relevance.append(chunk_rel)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing query: {item['question']}\")\n",
    "                    print(f\"Error details: {str(e)}\")\n",
    "                    # Add empty results for this query\n",
    "                    doc_relevance.append([])\n",
    "                    chunk_relevance.append([])\n",
    "                    search_times.append(0)\n",
    "            \n",
    "            total_time = time.time() - start_time\n",
    "            \n",
    "            results[name] = {\n",
    "                'doc_hit_rate': hit_rate(doc_relevance),\n",
    "                'doc_mrr': mrr(doc_relevance),\n",
    "                'chunk_hit_rate': hit_rate(chunk_relevance),\n",
    "                'chunk_mrr': mrr(chunk_relevance),\n",
    "                'total_time': total_time,\n",
    "                'avg_query_time': sum(search_times) / len(search_times) if search_times else 0,\n",
    "                'min_query_time': min(search_times) if search_times else 0,\n",
    "                'max_query_time': max(search_times) if search_times else 0\n",
    "            }\n",
    "            \n",
    "            # Save results after each successful evaluation\n",
    "            with open(results_file, 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "            \n",
    "            print(f\"Completed evaluation of {name}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {name}: {str(e)}\")\n",
    "            results[name] = {'error': str(e)}\n",
    "            \n",
    "            # Save results even if there was an error\n",
    "            with open(results_file, 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dadb91cb-a2d0-4a1f-9013-a7b2e17b822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation of Text Search\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f6f6a39f9748e7adc20b069c7e5da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Text Search:   0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed evaluation of Text Search\n",
      "Starting evaluation of Text Vector KNN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2e683be44f42b6af000944e49e3250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Text Vector KNN:   0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimi\\AppData\\Local\\Temp\\ipykernel_13912\\337455416.py:23: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  es_results = es_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed evaluation of Text Vector KNN\n",
      "Starting evaluation of Hybrid Search\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8f094379e1454da71d944d9a98dc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Hybrid Search:   0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimi\\AppData\\Local\\Temp\\ipykernel_13912\\462467289.py:31: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  es_results = es_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed evaluation of Hybrid Search\n",
      "Total Questions: 1950\n",
      "\n",
      "Evaluation Results:\n",
      "\n",
      "Text Search:\n",
      "  Document Hit Rate: 0.8349\n",
      "  Document MRR: 0.6939\n",
      "  Chunk Hit Rate: 0.8179\n",
      "  Chunk MRR: 0.6683\n",
      "  Total Evaluation Time: 124.00 seconds\n",
      "  Average Query Time: 63.23 ms\n",
      "  Min Query Time: 0.00 ms\n",
      "  Max Query Time: 98.97 ms\n",
      "\n",
      "Text Vector KNN:\n",
      "  Document Hit Rate: 0.7056\n",
      "  Document MRR: 0.5286\n",
      "  Chunk Hit Rate: 0.6641\n",
      "  Chunk MRR: 0.4871\n",
      "  Total Evaluation Time: 291.27 seconds\n",
      "  Average Query Time: 148.56 ms\n",
      "  Min Query Time: 116.75 ms\n",
      "  Max Query Time: 713.85 ms\n",
      "\n",
      "Hybrid Search:\n",
      "  Document Hit Rate: 0.8359\n",
      "  Document MRR: 0.6971\n",
      "  Chunk Hit Rate: 0.8195\n",
      "  Chunk MRR: 0.6716\n",
      "  Total Evaluation Time: 332.74 seconds\n",
      "  Average Query Time: 169.64 ms\n",
      "  Min Query Time: 96.06 ms\n",
      "  Max Query Time: 438.67 ms\n"
     ]
    }
   ],
   "source": [
    "search_functions = {\n",
    "    'Text Search': text_search,\n",
    "    'Text Vector KNN': lambda query, size=5, source=None: elastic_search_knn('text_vector', query, source),\n",
    "    'Hybrid Search': hybrid_search,\n",
    "}\n",
    "\n",
    "\n",
    "evaluation_results = evaluate_search_methods(ground_truth, search_functions)\n",
    "\n",
    "\n",
    "def print_evaluation_results(results):\n",
    "    print(f\"Total Questions: {results['total_questions']}\")\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    for method, metrics in results.items():\n",
    "        if method != 'total_questions':\n",
    "            print(f\"\\n{method}:\")\n",
    "            if isinstance(metrics, dict) and 'error' not in metrics:\n",
    "                print(f\"  Document Hit Rate: {metrics['doc_hit_rate']:.4f}\")\n",
    "                print(f\"  Document MRR: {metrics['doc_mrr']:.4f}\")\n",
    "                print(f\"  Chunk Hit Rate: {metrics['chunk_hit_rate']:.4f}\")\n",
    "                print(f\"  Chunk MRR: {metrics['chunk_mrr']:.4f}\")\n",
    "                print(f\"  Total Evaluation Time: {metrics['total_time']:.2f} seconds\")\n",
    "                print(f\"  Average Query Time: {metrics['avg_query_time']*1000:.2f} ms\")\n",
    "                print(f\"  Min Query Time: {metrics['min_query_time']*1000:.2f} ms\")\n",
    "                print(f\"  Max Query Time: {metrics['max_query_time']*1000:.2f} ms\")\n",
    "            else:\n",
    "                print(f\"  Error: {metrics.get('error', 'Unknown error occurred')}\")\n",
    "\n",
    "print_evaluation_results(evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592c1c1-5cc7-46f1-bee6-0f20e970319a",
   "metadata": {},
   "source": [
    "## Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70d7c583-e69a-41c6-8a46-3cd3f0d7a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rrf(rank, k=60):\n",
    "    \"\"\" Implementation of the relevance score \"\"\"\n",
    "    return 1 / (k + rank)\n",
    "\n",
    "def elastic_search_hybrid_rrf(query, k=60):\n",
    "    vector = model.encode(query).tolist()\n",
    "    \n",
    "    knn_query = {\n",
    "        \"field\": \"text_vector\",\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5\n",
    "    }\n",
    "\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"text^3\", \"title\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5,\n",
    "                    \"fuzziness\": \"AUTO\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    knn_results = es_client.search(\n",
    "        index=index_name, \n",
    "        body={\n",
    "            \"knn\": knn_query, \n",
    "            \"size\": 10\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    \n",
    "    keyword_results = es_client.search(\n",
    "        index=index_name, \n",
    "        body={\n",
    "            \"query\": keyword_query, \n",
    "            \"size\": 10\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    \n",
    "    rrf_scores = {}\n",
    "\n",
    "    for rank, hit in enumerate(knn_results):\n",
    "        doc_id = hit['_id']\n",
    "        rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    for rank, hit in enumerate(keyword_results):\n",
    "        doc_id = hit['_id']\n",
    "        if doc_id in rrf_scores:\n",
    "            rrf_scores[doc_id] += compute_rrf(rank + 1, k)\n",
    "        else:\n",
    "            rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-5 documents by the score\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:5]:\n",
    "        doc = es_client.get(index=index_name, id=doc_id)\n",
    "        final_results.append(doc['_source'])\n",
    "    \n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbe9de50-5e11-4783-b267-14b142c534b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing results. Continuing from where we left off.\n",
      "Skipping Text Search as it has already been evaluated.\n",
      "Skipping Text Vector KNN as it has already been evaluated.\n",
      "Skipping Hybrid Search as it has already been evaluated.\n",
      "Starting evaluation of Hybrid Search RRF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1dde82549240c4b6953cae234a7703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Hybrid Search RRF:   0%|          | 0/1950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimi\\AppData\\Local\\Temp\\ipykernel_13912\\3723986028.py:30: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  knn_results = es_client.search(\n",
      "C:\\Users\\dimi\\AppData\\Local\\Temp\\ipykernel_13912\\3723986028.py:38: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  keyword_results = es_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed evaluation of Hybrid Search RRF\n",
      "Total Questions: 1950\n",
      "\n",
      "Evaluation Results:\n",
      "\n",
      "Text Search:\n",
      "  Document Hit Rate: 0.8349\n",
      "  Document MRR: 0.6939\n",
      "  Chunk Hit Rate: 0.8179\n",
      "  Chunk MRR: 0.6683\n",
      "  Total Evaluation Time: 124.00 seconds\n",
      "  Average Query Time: 63.23 ms\n",
      "  Min Query Time: 0.00 ms\n",
      "  Max Query Time: 98.97 ms\n",
      "\n",
      "Text Vector KNN:\n",
      "  Document Hit Rate: 0.7056\n",
      "  Document MRR: 0.5286\n",
      "  Chunk Hit Rate: 0.6641\n",
      "  Chunk MRR: 0.4871\n",
      "  Total Evaluation Time: 291.27 seconds\n",
      "  Average Query Time: 148.56 ms\n",
      "  Min Query Time: 116.75 ms\n",
      "  Max Query Time: 713.85 ms\n",
      "\n",
      "Hybrid Search:\n",
      "  Document Hit Rate: 0.8359\n",
      "  Document MRR: 0.6971\n",
      "  Chunk Hit Rate: 0.8195\n",
      "  Chunk MRR: 0.6716\n",
      "  Total Evaluation Time: 332.74 seconds\n",
      "  Average Query Time: 169.64 ms\n",
      "  Min Query Time: 96.06 ms\n",
      "  Max Query Time: 438.67 ms\n",
      "\n",
      "Hybrid Search RRF:\n",
      "  Document Hit Rate: 0.8497\n",
      "  Document MRR: 0.6489\n",
      "  Chunk Hit Rate: 0.8328\n",
      "  Chunk MRR: 0.6159\n",
      "  Total Evaluation Time: 522.48 seconds\n",
      "  Average Query Time: 267.18 ms\n",
      "  Min Query Time: 214.56 ms\n",
      "  Max Query Time: 516.88 ms\n"
     ]
    }
   ],
   "source": [
    "search_functions['Hybrid Search RRF'] = elastic_search_hybrid_rrf\n",
    "\n",
    "evaluation_results = evaluate_search_methods(ground_truth, search_functions)\n",
    "print_evaluation_results(evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3310d93-6e14-4678-bf10-5a01f3ac62f2",
   "metadata": {},
   "source": [
    "#### Hybrid Search RRF seems the best. Text Search is very close and is 4.5 times faster than Hybrid Search RRF and 2.5 times faster than Hybrid Search, so I will using it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb7facb-002c-4e2a-ac41-fde687ad31dc",
   "metadata": {},
   "source": [
    "# RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "876af398-c586-4a9e-9e61-ae429de1db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, size=3, model='gpt-4o-mini', source=None):\n",
    "    search_results = text_search(query, size, source)\n",
    "    prompt, context = build_prompt(query, search_results)\n",
    "    answer = llm(prompt, model=model, max_tokens=250)  # Increased from 150 to 300\n",
    "    return {\n",
    "        'query': query,\n",
    "        'context': context,\n",
    "        'prompt': prompt,\n",
    "        'answer': answer,\n",
    "        'search_results': search_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30efbb95-fb84-4ba0-9296-cc4e7563ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How does Razor DAO determine which users are awarded the R-1 role?\n",
      "Answer: Razor DAO awards the R-1 role to users who actively contribute to the project's development by using the platform or promoting it within their networks. The criteria for receiving this role are based on genuine actions rather than specific tasks, making it accessible to users who are actively engaged in supporting Razor DAO's growth. While there are no guaranteed methods to obtain the R-1 role, the DAO is attentive to contributions and recognizes those who demonstrate a commitment to the community.\n",
      "\n",
      "To increase their chances of being awarded the R-1 role, users should complete tasks such as staying updated with zealy tasks in the #razor-missions channel and creating detailed threads about the Razor DAO on social media, ensuring to tag the DAO and Movement Labs. Genuine discussions with friends about the project, driven by a belief in its mission rather than a mere promotional effort, are also encouraged. Although the role is awarded for active support, extended inactivity after receiving the role may lead to a loss of the R-1 designation, although this is deemed unlikely.\n"
     ]
    }
   ],
   "source": [
    "question = 'How does Razor DAO determine which users are awarded the R-1 role?'\n",
    "\n",
    "result = rag(question, size=3, model='gpt-4o-mini', source=None)\n",
    "print(f\"Question: {result['query']}\")\n",
    "print(f\"Answer: {result['answer']}\")\n",
    "# print(f\"\\nContext: {result['context']}\")\n",
    "# print(f\"\\nPrompt: {result['prompt']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b8bd8-58c6-4c64-a731-866f7efcd765",
   "metadata": {},
   "source": [
    "## RAG evaluation - LLM-as-a-Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68a1588a-fd7f-49f4-92ac-7ff11766bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73718a96-687f-4fb2-b6ed-914aea7599e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming ground_truth data is already available\n",
    "df_question = pd.DataFrame(ground_truth)\n",
    "df_sample = df_question.sample(n=100, random_state=1)\n",
    "sample = df_sample.to_dict(orient='records')\n",
    "\n",
    "# Define models to compare\n",
    "models = ['gpt-4o-mini', 'gpt-4o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2f3c003-295d-4c4d-84c0-4b61f9053dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dee13c6f-951b-4ba1-9f4f-9d6946964d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with model: gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG with gpt-4o-mini:  66%|████████████████████████████████████████████▏                      | 66/100 [04:09<02:07,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing evaluation for question: What is the title of the document?\n",
      "Raw evaluation: {\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer directly provides the title of the document requested in the question, specifically stating 'The title of the document is \"Introduction | Movewiffrens.\"' This aligns perfectly with the query about the document's title.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG with gpt-4o-mini: 100%|██████████████████████████████████████████████████████████████████| 100/100 [06:28<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Distribution for gpt-4o-mini:\n",
      "relevance\n",
      "RELEVANT           0.919192\n",
      "NON_RELEVANT       0.040404\n",
      "PARTLY_RELEVANT    0.040404\n",
      "Name: proportion, dtype: float64\n",
      "Saved results to rag-eval-results-gpt-4o-mini.csv\n",
      "Evaluation Results for gpt-4o-mini:\n",
      "* 91 (91.9%) `RELEVANT`\n",
      "* 4 (4.0%) `PARTLY_RELEVANT`\n",
      "* 4 (4.0%) `NON_RELEVANT`\n",
      "\n",
      "Non-Relevant Answers for gpt-4o-mini:\n",
      "Question: What is the main purpose of the Razor DAO?\n",
      "Answer: The context provided does not contain information regarding the main purpose of the Razor DAO. Please provide additional details or specify another resource where this information might be found.\n",
      "Explanation: The generated answer does not address the question about the main purpose of the Razor DAO. Instead, it states a lack of information and requests additional details, which does not provide any relevant content concerning the main purpose of the Razor DAO.\n",
      "--------------------------------------------------\n",
      "Question: What do users need to do to register successfully on the RIZE platform?\n",
      "Answer: The provided context does not include direct information on how to register successfully on the RIZE platform. If you can provide additional details or specify what you are looking for in the registration process, I would be able to assist you better. Please clarify your question or provide more context about the RIZE platform's registration requirements.\n",
      "Explanation: The generated answer does not provide any specific information or guidance related to the question about registering on the RIZE platform. It acknowledges a lack of context and suggests the user clarify their question, which does not directly address the user's needs regarding successful registration.\n",
      "--------------------------------------------------\n",
      "Question: What are the two methods available for retrieving blocks according to their specifications?\n",
      "Answer: The two methods available for retrieving blocks according to their specifications are not explicitly detailed in the provided context. If you could clarify whether you are looking for specific retrieval methods within a certain aspect of blockchain implementation (like querying a blockchain network, accessing specific protocols, etc.), that would help provide a more accurate answer. Without additional context, there are no direct methods mentioned in the content given. \n",
      "\n",
      "Please provide more details or specify which aspects you are referring to so I can assist you better.\n",
      "Explanation: The generated answer does not provide any relevant information about the two methods for retrieving blocks according to their specifications as requested in the question. Instead, it indicates a lack of information and asks for clarification, which does not address the question directly.\n",
      "--------------------------------------------------\n",
      "Question: How many chains does the Pyth Network support?\n",
      "Answer: The context provided does not specify the number of chains that the Pyth Network supports. It primarily focuses on the use of Pyth SDK for price feeds within the Movement Network and contains technical details about installing and utilizing the SDK. \n",
      "\n",
      "To find the specific number of chains supported by the Pyth Network, you may need to refer to Pyth's official documentation or website. If you have more specific details or contexts about the Pyth Network that you can share, I would be glad to help!\n",
      "Explanation: The generated answer does not directly address the question about the number of chains supported by the Pyth Network. Instead, it discusses the Pyth SDK and suggests referring to official documentation, which does not provide the requested information.\n",
      "--------------------------------------------------\n",
      "Evaluating with model: gpt-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG with gpt-4o: 100%|███████████████████████████████████████████████████████████████████████| 100/100 [06:11<00:00,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Distribution for gpt-4o:\n",
      "relevance\n",
      "RELEVANT           0.79\n",
      "PARTLY_RELEVANT    0.15\n",
      "NON_RELEVANT       0.06\n",
      "Name: proportion, dtype: float64\n",
      "Saved results to rag-eval-results-gpt-4o.csv\n",
      "Evaluation Results for gpt-4o:\n",
      "* 79 (79.0%) `RELEVANT`\n",
      "* 15 (15.0%) `PARTLY_RELEVANT`\n",
      "* 6 (6.0%) `NON_RELEVANT`\n",
      "\n",
      "Non-Relevant Answers for gpt-4o:\n",
      "Question: What is the main purpose of the Razor DAO?\n",
      "Answer: The CONTEXT provided does not contain specific information about Razor DAO or its main purpose. Please provide more details or clarify your question. For example, if you have a specific document, link, or section in mind that discusses Razor DAO, sharing that would help in providing a more precise answer.\n",
      "Explanation: The generated answer does not provide any information about the main purpose of Razor DAO. Instead, it requests more details or clarification, which does not address the question asked.\n",
      "--------------------------------------------------\n",
      "Question: How many people have participated in the Get Off Your Butt & Work Off event?\n",
      "Answer: The total number of people who have participated in the \"Get Off Your Butt & Work Off\" event is **17**.\n",
      "\n",
      "This is derived from the total mentioned in two different documents:\n",
      "- In one document, it states: \"People have already participated: 10 : 5 der Leck : 2\".\n",
      "- In another document, it mentions: \"People have already participated: 11 : 4 der Leck : 2\".\n",
      "\n",
      "Adding these, we have 11 general participants, 4 from \"der Leck\", and 2 from another specified group, totaling: 11 + 4 + 2 = 17 participants.\n",
      "Explanation: The generated answer misinterprets the information from the documents. Instead of summing the participant data from the two documents, it incorrectly combines them. The correct approach would be to recognize that the documents list different counts of participants, and the total should not be the sum of these different counts. Thus, the final count of 17 participants is inaccurate, making the answer non-relevant.\n",
      "--------------------------------------------------\n",
      "Question: What do users need to do to register successfully on the RIZE platform?\n",
      "Answer: The provided CONTEXT does not include specific steps for users to register on the RIZE platform. To address your question accurately, please provide additional details or clarify the requirements for registration, such as the specific steps or any prerequisites needed for the registration process on RIZE. This will help me give you a suitably detailed response.\n",
      "Explanation: The generated answer does not provide any specific information about the steps or prerequisites required for users to register on the RIZE platform. Instead, it requests additional context or details, thereby failing to address the question directly.\n",
      "--------------------------------------------------\n",
      "Question: What are the two methods available for retrieving blocks according to their specifications?\n",
      "Answer: The CONTEXT provided does not detail the methods available for retrieving blocks according to their specifications. If you need information on a specific aspect related to retrieving blocks in the Movement Network ecosystem or using the Move language, please provide additional details or clarify your question.\n",
      "Explanation: The generated answer fails to provide information regarding the methods for retrieving blocks according to their specifications, which was the core requirement of the question. Instead, it mentions the lack of context details and suggests providing additional information, which does not address the question directly or partially.\n",
      "--------------------------------------------------\n",
      "Question: What parameters are necessary to call the update_strategy_max_report_delay function?\n",
      "Answer: The CONTEXT provided does not contain specific details about the `update_strategy_max_report_delay` function or the parameters necessary to call it.\n",
      "\n",
      "Please provide more information or context about the `update_strategy_max_report_delay` function so that I can assist you accurately. For example, the module name where this function is defined or a reference to its documentation would be helpful.\n",
      "Explanation: The generated answer does not provide any specific information about the parameters necessary to call the `update_strategy_max_report_delay` function. Instead, it requests more context or details, which does not address the question directly.\n",
      "--------------------------------------------------\n",
      "Question: Which channels are mentioned as deleted in relation to the event participation?\n",
      "Answer: The channels mentioned as deleted in relation to event participation are `#deleted-channel` and `#deleted-channel`. This indicates that specific channels referenced for the event feedback or participation details are no longer available.\n",
      "\n",
      "If you need more details about these channels or their previous roles, please provide additional context or clarify your question.\n",
      "Explanation: The generated answer does not specify the actual channel names and only uses placeholder text `#deleted-channel`. It does not provide any specific information relevant to the question about which channels are deleted in relation to event participation.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f\"Evaluating with model: {model}\")\n",
    "    \n",
    "    evaluations = []\n",
    "    \n",
    "    for record in tqdm(sample, desc=f\"Evaluating RAG with {model}\"):\n",
    "        question = record['question']\n",
    "        rag_result = rag(question, size=3, model=model, source=None)\n",
    "        answer = rag_result['answer'] \n",
    "        \n",
    "        prompt = prompt2_template.format(\n",
    "            question=question,\n",
    "            answer=answer\n",
    "        )\n",
    "        \n",
    "        evaluation = llm(prompt, model=model, max_tokens=150)\n",
    "        try:\n",
    "            evaluation = json.loads(evaluation)\n",
    "            evaluations.append({\n",
    "                'doc_id': record['doc_id'],\n",
    "                'chunk_id': record['chunk_id'],\n",
    "                'question': question,\n",
    "                'answer': answer,\n",
    "                'relevance': evaluation['Relevance'],\n",
    "                'explanation': evaluation['Explanation']\n",
    "            })\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing evaluation for question: {question}\")\n",
    "            print(\"Raw evaluation:\", evaluation)\n",
    "\n",
    "    df_eval = pd.DataFrame(evaluations)\n",
    "\n",
    "    relevance_distribution = df_eval['relevance'].value_counts(normalize=True)\n",
    "    print(f\"Relevance Distribution for {model}:\")\n",
    "    print(relevance_distribution)\n",
    "\n",
    "    csv_filename = f'rag-eval-results-{model}.csv'\n",
    "    df_eval.to_csv(csv_filename, index=False)\n",
    "    print(f\"Saved results to {csv_filename}\")\n",
    "\n",
    "    relevance_counts = df_eval['relevance'].value_counts()\n",
    "    total_evaluations = len(df_eval)\n",
    "    \n",
    "    print(f\"Evaluation Results for {model}:\")\n",
    "    for category in ['RELEVANT', 'PARTLY_RELEVANT', 'NON_RELEVANT']:\n",
    "        count = relevance_counts.get(category, 0)\n",
    "        percentage = (count / total_evaluations) * 100\n",
    "        print(f\"* {count} ({percentage:.1f}%) `{category}`\")\n",
    "\n",
    "    print(f\"\\nNon-Relevant Answers for {model}:\")\n",
    "    non_relevant = df_eval[df_eval['relevance'] == 'NON_RELEVANT']\n",
    "    for _, row in non_relevant.iterrows():\n",
    "        print(f\"Question: {row['question']}\")\n",
    "        print(f\"Answer: {row['answer']}\")\n",
    "        print(f\"Explanation: {row['explanation']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e52b0-1361-4197-88f9-ee7ff74e745a",
   "metadata": {},
   "source": [
    "### User query rewriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "49ea1364-6df6-4045-ba1a-a00acb00e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query(original_query, model='gpt-4o-mini'):\n",
    "    rewrite_prompt = f\"\"\"\n",
    "    You are a helpful assistant skilled at refining questions to make them clearer and more specific. \n",
    "    Please rewrite the following query by breaking it down into more precise terms, adding context if necessary, \n",
    "    and ensuring it can be answered easily. \n",
    "    Do not include any additional comments or explanations.\n",
    "\n",
    "    Consider aspects such as specificity, clarity, and context. \n",
    "\n",
    "    Original query: {original_query}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": rewrite_prompt}],\n",
    "            max_tokens=80  # Adjust as needed for length\n",
    "        )\n",
    "        rewritten_query = response.choices[0].message.content.strip()\n",
    "        return rewritten_query\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during query rewriting: {e}\")\n",
    "        return original_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8f11aeeb-49ab-4e16-923a-e50c867d5f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_rewritten(query, size=3, model='gpt-4o-mini', source=None):\n",
    "    rewritten_query = rewrite_query(query, model)\n",
    "    search_results = text_search(rewritten_query, size, source)\n",
    "    prompt, context = build_prompt(rewritten_query, search_results)\n",
    "    answer = llm(prompt, model=model, max_tokens=250)\n",
    "    return {\n",
    "        'original_query': query,\n",
    "        'rewritten_query': rewritten_query,\n",
    "        'context': context,\n",
    "        'prompt': prompt,\n",
    "        'answer': answer,\n",
    "        'search_results': search_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b86e1160-82f8-40cb-bb05-64a0b065373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the main purpose of the Razor DAO?\n",
      "Question: What is the primary objective or goal of the Razor Decentralized Autonomous Organization (DAO)?\n",
      "Answer: The primary objective of the Razor Decentralized Autonomous Organization (DAO) is to support and enhance the Movement Labs ecosystem by providing essential services like a native wallet and a decentralized exchange protocol (RazorDex) across the M1, M2, and MEVM networks. This facilitates secure and efficient transactions within the ecosystem, enabling users to manage their digital assets seamlessly.\n",
      "\n",
      "RazorDAO aims to foster a decentralized finance environment by empowering users with direct control over their funds and trading activities through these innovative tools. The organization promotes community-driven governance and participation, aligning with the core principles of decentralization and user empowerment in the Movement Network.\n"
     ]
    }
   ],
   "source": [
    "question = 'What is the main purpose of the Razor DAO?'\n",
    "\n",
    "result = rag_rewritten(question, size=3, model='gpt-4o-mini', source=None)\n",
    "print(f\"Question: {result['original_query']}\")\n",
    "print(f\"Question: {result['rewritten_query']}\")\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f43c1e1b-4c68-4cb4-839b-08569a39f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag_rewritten(sample, model):\n",
    "    evaluations = []\n",
    "    \n",
    "    for record in tqdm(sample, desc=f\"Evaluating RAG with {model}\"):\n",
    "        question = record['question']\n",
    "        rag_result = rag_rewritten(question, size=3, model=model, source=None)\n",
    "        answer = rag_result['answer']\n",
    "        rewritten_query = rag_result['rewritten_query']\n",
    "        \n",
    "        prompt = prompt2_template.format(\n",
    "            question=question,\n",
    "            answer=answer\n",
    "        )\n",
    "        \n",
    "        evaluation = llm(prompt, model=model, max_tokens=150)\n",
    "        try:\n",
    "            evaluation = json.loads(evaluation)\n",
    "            evaluations.append({\n",
    "                'doc_id': record['doc_id'],\n",
    "                'chunk_id': record['chunk_id'],\n",
    "                'original_question': question,\n",
    "                'rewritten_question': rewritten_query,\n",
    "                'answer': answer,\n",
    "                'relevance': evaluation['Relevance'],\n",
    "                'explanation': evaluation['Explanation']\n",
    "            })\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing evaluation for question: {question}\")\n",
    "            print(\"Raw evaluation:\", evaluation)\n",
    "    \n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a669f2d5-7d21-42f7-9101-a1d4e386d3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with model: gpt-4o-mini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG with gpt-4o-mini: 100%|██████████████████████████████████████████████████████████████████| 100/100 [09:28<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Distribution for gpt-4o-mini:\n",
      "relevance\n",
      "RELEVANT           0.82\n",
      "PARTLY_RELEVANT    0.10\n",
      "NON_RELEVANT       0.08\n",
      "Name: proportion, dtype: float64\n",
      "Saved results to rag-eval-results-with-rewriting-gpt-4o-mini.csv\n",
      "Evaluation Results for gpt-4o-mini:\n",
      "* 82 (82.0%) `RELEVANT`\n",
      "* 10 (10.0%) `PARTLY_RELEVANT`\n",
      "* 8 (8.0%) `NON_RELEVANT`\n",
      "\n",
      "Non-Relevant Answers for gpt-4o-mini:\n",
      "Original Question: What is the objective of Mission 4 in the Seekers Alliance?\n",
      "Rewritten Question: What is the specific goal or objective of Mission 4 within the Seekers Alliance game or organization? Please provide details about the mission's requirements and intended outcomes.\n",
      "Answer: The provided context does not include specific information regarding \"Mission 4\" within the Seekers Alliance. It details Missions 1 through 2 and mentions ongoing activities, but there are no explicit requirements or outcomes associated with Mission 4.\n",
      "\n",
      "If you have any additional details or another source regarding Mission 4, please share that information, and I can assist you further.\n",
      "Explanation: The generated answer does not provide any specific information regarding the objective of Mission 4, as it states that there is no information available about it. Since the question is directly asking for the objective of Mission 4, the lack of relevant content renders the answer non-relevant.\n",
      "--------------------------------------------------\n",
      "Original Question: What is the minimum duration left for the Testnet experience according to the document?\n",
      "Rewritten Question: What is the minimum remaining duration for the Testnet experience specified in the provided document? Please include any relevant dates or timelines mentioned.\n",
      "Answer: The provided context does not mention the minimum remaining duration for the Testnet experience or any specific dates or timelines related to it. If there are other documents or sources that contain this information, please share them, or clarify your request so I can assist you better.\n",
      "Explanation: The generated answer states that the context does not provide any information about the minimum duration left for the Testnet experience, which directly addresses the question. Since it does not offer any information or insights regarding the query, it is classified as non-relevant.\n",
      "--------------------------------------------------\n",
      "Original Question: What are the possible values for the node_role field in the ledger information?\n",
      "Rewritten Question: What are the specific possible values for the \"node_role\" field in the ledger information? Can you provide examples of each value and explain their significance or intended use within the context of the ledger?\n",
      "Answer: The context provided does not specify the possible values for the \"node_role\" field in the ledger information. It focuses mainly on account resources and Move struct types relevant to the Movement Network and Move language but does not mention \"node_role\" or its potential values.\n",
      "\n",
      "To better assist you, could you provide more context or refer to a specific documentation link that outlines the \"node_role\" field? This would help in delivering a precise answer regarding its values and significance.\n",
      "Explanation: The generated answer does not provide any information related to the possible values for the 'node_role' field. Instead, it indicates a lack of relevant context and asks for additional information, which does not address the original question.\n",
      "--------------------------------------------------\n",
      "Original Question: How does Stable Jack mitigate the risk of price divergence between futures and spot prices in crypto markets?\n",
      "Rewritten Question: What strategies does Stable Jack use to reduce the risk of price divergence between futures and spot prices in the cryptocurrency markets? Could you provide specific examples of these strategies and explain how they function?\n",
      "Answer: The context provided does not specifically describe strategies used by Stable Jack to mitigate the risk of price divergence between futures and spot prices in the cryptocurrency markets. It primarily focuses on the characteristics and advantages of xAVAX and aUSD within the Stable Jack ecosystem. If you have specific strategies or mechanisms in mind that Stable Jack employs, please provide additional details or context. This will help me give you a more accurate and comprehensive response regarding their methods for addressing price divergence.\n",
      "Explanation: The generated answer does not address the question regarding how Stable Jack mitigates the risk of price divergence between futures and spot prices. Instead, it mentions a lack of information about Stable Jack's strategies and shifts focus to other aspects of the ecosystem, making it irrelevant to the specific inquiry.\n",
      "--------------------------------------------------\n",
      "Original Question: What is currently down on the Movement Sui network?\n",
      "Rewritten Question: Could you provide details about any current outages or issues affecting the Movement Sui network? Specifically, what services or functionalities are impacted at this moment?\n",
      "Answer: The provided context does not include any specific information regarding current outages or issues affecting the Movement Sui network. It mainly covers details about faucet services for various networks, including Sui, but does not mention any service disruptions or malfunctions.\n",
      "\n",
      "For precise updates or to know if any functionalities or services are impacted on the Movement Sui network, it would be best to check the official Movement Labs channels, such as their website or community Discord, or consult status pages if available. If you have access to more specific details or a different context regarding current outages, please share them for a more tailored response.\n",
      "Explanation: The generated answer does not address the question regarding current outages on the Movement Sui network, as it explicitly states that no specific information is available about any issues. It also suggests checking external sources for updates, which does not answer the question directly.\n",
      "--------------------------------------------------\n",
      "Original Question: What is the user's responsibility regarding transaction fees on OmniLending?\n",
      "Rewritten Question: What specific responsibilities does a user have concerning transaction fees when using the OmniLending platform? Please provide details about any fees that users are expected to pay and any conditions that may apply.\n",
      "Answer: The provided context does not contain specific information about transaction fees or user responsibilities related to the OmniLending platform. To accurately answer your question regarding transaction fees and conditions associated with OmniLending, I would need further details or documentation specifically related to OmniLending and its fee structures.\n",
      "\n",
      "Please provide additional information or specify the relevant section concerning OmniLending's transaction fees and user responsibilities.\n",
      "Explanation: The generated answer does not address the user's responsibility regarding transaction fees on OmniLending, as it states there is no information available on the topic and requests further details. Therefore, it is not relevant to the question asked.\n",
      "--------------------------------------------------\n",
      "Original Question: What key milestones are planned for WarpGate in Q4 2023?\n",
      "Rewritten Question: What are the specific key milestones planned for WarpGate in the fourth quarter of 2023? Please include dates, objectives, and any relevant metrics for success.\n",
      "Answer: The available context does not provide specific key milestones planned for WarpGate in the fourth quarter of 2023, including dates, objectives, or relevant metrics for success. The details mainly focus on the features of the WarpGate Launchpad, its offerings, and its security audit results, but there are no announcements or timelines for upcoming milestones.\n",
      "\n",
      "If you require precise information regarding planned milestones for WarpGate in that timeframe, please provide additional context or check relevant resources or announcements from the WarpGate team.\n",
      "Explanation: The generated answer explicitly states that it does not provide the specific key milestones planned for WarpGate in Q4 2023, which is the direct information requested by the question. It also suggests seeking additional context or resources, indicating a complete lack of relevant information about the planned milestones.\n",
      "--------------------------------------------------\n",
      "Original Question: What is the expected release date for the testnet frontend (web) beta?\n",
      "Rewritten Question: What is the expected release date for the beta version of the web frontend for the testnet? Please provide any official announcements or updates related to this release.\n",
      "Answer: The provided context does not contain specific information regarding the expected release date for the beta version of the web frontend for the testnet. Furthermore, there are no official announcements or updates related to this release in the available documents.\n",
      "\n",
      "For accurate and timely updates, consider checking the official Movement Network channels or forums, where announcements are likely to be made. If you have additional details or a different context that could provide more clarity on this topic, please share!\n",
      "Explanation: The generated answer does not provide any information regarding the expected release date for the testnet frontend beta. It states that the necessary information is absent from the provided context and suggests external sources for updates, which does not address the question directly.\n",
      "--------------------------------------------------\n",
      "Evaluating with model: gpt-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating RAG with gpt-4o: 100%|███████████████████████████████████████████████████████████████████████| 100/100 [12:59<00:00,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Distribution for gpt-4o:\n",
      "relevance\n",
      "RELEVANT           0.61\n",
      "PARTLY_RELEVANT    0.23\n",
      "NON_RELEVANT       0.16\n",
      "Name: proportion, dtype: float64\n",
      "Saved results to rag-eval-results-with-rewriting-gpt-4o.csv\n",
      "Evaluation Results for gpt-4o:\n",
      "* 61 (61.0%) `RELEVANT`\n",
      "* 23 (23.0%) `PARTLY_RELEVANT`\n",
      "* 16 (16.0%) `NON_RELEVANT`\n",
      "\n",
      "Non-Relevant Answers for gpt-4o:\n",
      "Original Question: What is the main purpose of the Razor DAO?\n",
      "Rewritten Question: What is the primary objective of the Razor Decentralized Autonomous Organization (DAO)?\n",
      "\n",
      "- Could you describe the core mission or goal of Razor DAO?\n",
      "- What key functions or activities does Razor DAO focus on?\n",
      "- How does Razor DAO differentiate itself from other DAOs?\n",
      "Answer: The CONTEXT does not contain specific information about the Razor Decentralized Autonomous Organization (DAO), its core mission, key functions, or how it differentiates itself from other DAOs. \n",
      "\n",
      "To provide an accurate answer, please provide more information or clarify your question about the Razor DAO, if available from other sources or documents. If you can share any references or details related to Razor DAO, I will be able to assist you more effectively.\n",
      "Explanation: The generated answer does not provide any information about the main purpose of the Razor DAO. Instead, it states a lack of information in the provided context and requests additional details, which does not address the question directly.\n",
      "--------------------------------------------------\n",
      "Original Question: How many people have participated in the Get Off Your Butt & Work Off event?\n",
      "Rewritten Question: What is the total number of participants who have attended the \"Get Off Your Butt & Work Off\" event?\n",
      "Answer: The provided CONTEXT does not include information about the total number of participants for the \"Get Off Your Butt & Work Off\" event. \n",
      "\n",
      "Please provide additional details or specify where I can find the information about the number of participants.\n",
      "Explanation: The generated answer does not provide any relevant information about the number of participants in the 'Get Off Your Butt & Work Off' event. It merely states that the context does not have the information and asks for more details.\n",
      "--------------------------------------------------\n",
      "Original Question: What do users need to do to register successfully on the RIZE platform?\n",
      "Rewritten Question: 1. What information is required from users during the registration process on the RIZE platform?\n",
      "2. Are there any specific eligibility criteria or requirements that users must meet to register on RIZE?\n",
      "3. Could you outline the step-by-step process for registering on the RIZE platform?\n",
      "4. Are there any common issues users encounter during registration, and how can they be resolved?\n",
      "5. Is there any\n",
      "Answer: The provided CONTEXT does not contain sufficient details about the RIZE platform's registration process, eligibility criteria, step-by-step instructions, common issues or their resolutions, or other specific queries related to user registration.\n",
      "\n",
      "Could you please provide more context or specify which document might contain the relevant information about the RIZE platform registration process? This will help me provide a more accurate and detailed response.\n",
      "Explanation: The generated answer does not directly address the question about what users need to do to register successfully on the RIZE platform. Instead, it refers to the lack of information in the provided context and requests more details or specific documents. It does not provide any tangible information or steps for the registration process on the RIZE platform.\n",
      "--------------------------------------------------\n",
      "Original Question: What does the red cross reaction indicate about the work submitted?\n",
      "Rewritten Question: 1. What does the red cross symbol typically signify in relation to submitted work?\n",
      "\n",
      "2. In what context is the red cross used when evaluating submitted work?\n",
      "\n",
      "3. Does a red cross on submitted work generally indicate a specific type of error or issue?\n",
      "\n",
      "4. How should one interpret the presence of a red cross in feedback on submitted work?\n",
      "\n",
      "5. What actions or corrections are usually required when a red\n",
      "Answer: The CONTEXT does not provide specific information about the use or interpretation of a red cross symbol in relation to submitted work. The focus of the provided document excerpts pertains to blockchain protocols, cross-chain functionality, and MoveVM enhancements, none of which directly address the concept of a red cross in submitted work evaluations.\n",
      "\n",
      "Please provide more information or clarify your question regarding the red cross in the context of submitted work so I can offer a precise answer.\n",
      "Explanation: The generated answer does not address the question about the red cross reaction related to submitted work. It discusses unrelated topics such as blockchain protocols and MoveVM enhancements, which are not pertinent to the original query.\n",
      "--------------------------------------------------\n",
      "Original Question: What types of SDKs are mentioned in the document related to the Swap integration?\n",
      "Rewritten Question: What specific types of Software Development Kits (SDKs) are referenced in the document regarding the integration of the Swap functionality?\n",
      "Answer: The Movement SDK features custom adaptors that facilitate integration with various blockchain networks and services. These adaptors are designed to interface seamlessly with sequencer networks and Data Availability (DA) services. Key elements supported by these adaptors include:\n",
      "\n",
      "- **Sequencer Networks**: The Movement SDK’s custom adaptors can interface with sequencer networks like Snowman and Proof of Stake (PoS) mechanisms, which helps maintain transaction ordering and strengthens blockchain resilience.\n",
      "- **Data Availability Services**: The adaptors enhance support for various Data Availability layers, including Ethereum-4844, Celestia, EigenDA, and Avail. This integration ensures data is accessible and transactions can be validated, supporting a transparent and reliable blockchain network.\n",
      "- **Validator Set Management**: These adaptors also play a crucial role in managing and reconfiguring validator sets, which is essential for maintaining consensus mechanism integrity and security.\n",
      "\n",
      "For a specific example, GAIMIN.io leverages the Movement SDK’s custom adaptors to enable interoperability across multiple blockchains like Ethereum and Binance Smart Chain, facilitating the transfer of assets and enhancing gaming experiences.\n",
      "Explanation: The generated answer discusses the Movement SDK and related adaptors for blockchain integration but does not directly address the types of SDKs related to the Swap integration mentioned in the question. Therefore, it does not provide the relevant information to answer the question.\n",
      "--------------------------------------------------\n",
      "Original Question: Which tokens can be accessed within the DegenHive protocol treasury?\n",
      "Rewritten Question: 1. What are the names of the tokens currently held in the DegenHive protocol treasury?\n",
      "2. Could you provide the specific allocations or quantities of each token in the DegenHive treasury?\n",
      "3. Are there any recent changes or updates to the list of tokens in the DegenHive protocol treasury? \n",
      "4. What criteria does the DegenHive protocol use to decide which tokens to hold in\n",
      "Answer: The provided CONTEXT does not include specific information about the names of tokens held in the DegenHive protocol treasury, their allocations or quantities, any recent changes to the list of tokens, or the criteria used by the DegenHive protocol to decide which tokens to hold.\n",
      "\n",
      "To respond accurately to your questions, I would need more details or access to additional documents that describe the token holdings, their allocations, updates to the treasury, and the criteria used by the protocol for holding tokens. If you could provide more information or specify the section of documentation that contains these details, I can offer a more complete and precise answer.\n",
      "Explanation: The generated answer does not provide any information about the tokens accessible within the DegenHive protocol treasury. Instead, it discusses the lack of relevant information in the provided context and requests additional details, which does not fulfill the requirement of addressing the specific question asked.\n",
      "--------------------------------------------------\n",
      "Original Question: What are the two methods available for retrieving blocks according to their specifications?\n",
      "Rewritten Question: 1. What are the two primary methods used to retrieve data blocks based on specific criteria?\n",
      "2. Can you describe the two main techniques for accessing blocks of data according to their defined parameters?\n",
      "Answer: Based on the provided context, the details to answer your questions about retrieving data blocks based on specific criteria are not explicitly covered. The context primarily includes information on the API endpoints for quoting swaps and retrieving account resources, but does not directly address the methods for data block retrieval.\n",
      "\n",
      "To provide an accurate answer, I would need more specific information on the context surrounding data block retrieval. For instance, are you referring to blockchain data, database entries, or another form of data management system? Please clarify the type of data blocks you are interested in and any relevant systems or protocols you're referring to. \n",
      "\n",
      "In the meantime, if you're looking into retrieving account resources specifically within the Movement Network, the \"GET /accounts/:address/resources\" endpoint is used to retrieve all account resources for a given account and a specific ledger version. Parameters such as `ledger_version` can be specified to target a particular version, or the latest version is used by default. Furthermore, pagination can be controlled using a cursor provided in responses.\n",
      "Explanation: The generated answer does not address the question about the methods available for retrieving blocks based on their specifications. Instead, it discusses unrelated topics such as API endpoints for quoting swaps and retrieving account resources, and requests for more context without providing any pertinent information on the requested methods.\n",
      "--------------------------------------------------\n",
      "Original Question: How does Stable Jack mitigate the risk of price divergence between futures and spot prices in crypto markets?\n",
      "Rewritten Question: 1. What specific strategies does Stable Jack employ to manage the risk of price divergence between futures contracts and spot prices in cryptocurrency markets?\n",
      "2. How effective has Stable Jack's approach been in preventing significant discrepancies between futures and spot prices?\n",
      "3. Can you provide examples or case studies where Stable Jack successfully mitigated price divergence in the crypto market?\n",
      "4. What types of technical analysis or tools does Stable Jack\n",
      "Answer: The provided context does not detail the specific strategies that Stable Jack employs to manage the risk of price divergence between futures contracts and spot prices in cryptocurrency markets, nor the effectiveness of these strategies or case studies. Additionally, technical analysis or tools utilized by Stable Jack are not mentioned in the given context.\n",
      "\n",
      "To provide accurate and detailed responses to the questions about Stable Jack's risk management strategies, effectiveness, case studies, and technical tools, it would be helpful to have more information explicitly related to these aspects. Please provide additional context or specify the details you are looking for within the context of Stable Jack's operations.\n",
      "Explanation: The generated answer states that the provided context does not include specific strategies employed by Stable Jack to manage price divergence risk, and it requests more information to answer the question accurately. It does not provide any relevant information or attempt to answer how Stable Jack mitigates the risk of price divergence between futures and spot prices in crypto markets.\n",
      "--------------------------------------------------\n",
      "Original Question: What should you do to disable the GitHub workflow that runs type and lint error checks on code pushes to the main branch?\n",
      "Rewritten Question: 1. Which GitHub repository contains the workflow you want to disable? (e.g., \"username/repository-name\")\n",
      "2. What is the name of the GitHub Actions workflow file that performs type and lint error checks? (e.g., \"lint.yml\")\n",
      "3. Do you want to disable the workflow temporarily or permanently?\n",
      "4. Should the workflow be disabled for all branches or only for the\n",
      "Answer: To answer your questions:\n",
      "\n",
      "1. The GitHub repository containing the workflow you want to disable is not explicitly mentioned in the provided context. Please specify the exact repository name.\n",
      "\n",
      "2. The name of the GitHub Actions workflow file that performs type and lint error checks is `lint.yaml`.\n",
      "\n",
      "3. Do you want to disable the workflow temporarily or permanently?\n",
      "\n",
      "4. Should the workflow be disabled for all branches or only for a specific branch?\n",
      "\n",
      "Please provide additional details to better assist you.\n",
      "Explanation: The generated answer does not directly address the question of how to disable the GitHub workflow for type and lint error checks. Instead, it asks for additional details and provides information not pertinent to the specific request. The answer needed was the steps to disable the workflow, not further inquiries or unrelated details.\n",
      "--------------------------------------------------\n",
      "Original Question: What parameters are necessary to call the update_strategy_max_report_delay function?\n",
      "Rewritten Question: What is the purpose of the `update_strategy_max_report_delay` function?\n",
      "\n",
      "Which programming language is the `update_strategy_max_report_delay` function written in?\n",
      "\n",
      "What are the data types of the parameters needed to call the `update_strategy_max_report_delay` function?\n",
      "\n",
      "Are there any default values for the parameters of the `update_strategy_max_report_delay` function?\n",
      "\n",
      "Are there any constraints or conditions on the values\n",
      "Answer: The provided CONTEXT does not contain specific information about the `update_strategy_max_report_delay` function, including its purpose, the programming language it is written in, the data types of its parameters, default values, or any constraints or conditions on the values.\n",
      "\n",
      "To provide accurate and complete information, please provide more context or direct sources where the `update_strategy_max_report_delay` function is defined or described. This will help in offering precise details about the function and its usage.\n",
      "Explanation: The generated answer does not provide information about the necessary parameters for the `update_strategy_max_report_delay` function. Instead, it discusses the lack of context and asks for more information, which does not address the query directly.\n",
      "--------------------------------------------------\n",
      "Original Question: What is currently down on the Movement Sui network?\n",
      "Rewritten Question: Can you provide a detailed status update on any current issues or outages affecting the Movement Sui network? Specifically, include:\n",
      "\n",
      "1. What services or components are currently down or experiencing issues?\n",
      "2. When did these issues start?\n",
      "3. Is there an estimated time for resolution?\n",
      "4. Are there any known causes for the current problems?\n",
      "5. How are users being impacted by the downtime?\n",
      "Answer: The CONTEXT provided does not contain any information about current issues or outages affecting the Movement Sui network. It mainly discusses updates and fixes for the Infinite Seas game, details on the Parthenon Wallets, and information on security and settlement mechanisms in the Movement Network.\n",
      "\n",
      "To provide a detailed status update on any current issues or outages affecting the Movement Sui network (including services down, start time, estimated resolution, known causes, and user impact), I need specific information about such events. Could you provide more details or clarify your query further?\n",
      "Explanation: The generated answer does not provide any information about what is currently down on the Movement Sui network. Instead, it states that the context provided does not contain information about current issues or outages and asks for more details or clarification. This does not address the user's specific query about the current status of the Movement Sui network.\n",
      "--------------------------------------------------\n",
      "Original Question: What key milestones are planned for WarpGate in Q4 2023?\n",
      "Rewritten Question: What specific milestones has WarpGate scheduled for the fourth quarter of 2023?\n",
      "- Are there any product launches or updates planned?\n",
      "- Are there any marketing campaigns or events scheduled?\n",
      "- Will there be any significant partnerships or collaborations announced?\n",
      "- Are there any internal initiatives, such as hiring or team expansions, expected?\n",
      "- Will there be any financial or performance targets set for this period?\n",
      "Answer: The CONTEXT provided does not contain any specific milestones, product launches, updates, marketing campaigns, events, partnerships, collaborations, internal initiatives, or financial targets scheduled for WarpGate in the fourth quarter of 2023. \n",
      "\n",
      "Please provide more detailed information or access to specific documents or sources directly related to WarpGate's Q4 2023 schedule for accurate and comprehensive answers.\n",
      "Explanation: The generated answer does not provide any specific information about the key milestones planned for WarpGate in Q4 2023. It only states that such information is not available in the provided context and asks for more detailed information. Consequently, it does not address the question directly.\n",
      "--------------------------------------------------\n",
      "Original Question: What is the title of the document?\n",
      "Rewritten Question: 1. What is the main subject or topic of the document?\n",
      "2. What is the publication date of the document?\n",
      "3. Who is the author or organization responsible for the document?\n",
      "4. Where was the document published or distributed?\n",
      "5. How would one typically reference this document in a bibliography?\n",
      "Answer: To address the questions based on the CONTEXT provided:\n",
      "\n",
      "1. **What is the main subject or topic of the document?**\n",
      "   - The main subject of the first document is an introduction and overview of Movewiffrens (MWFs), a blockchain-based social media platform. It explains the platform's features, functionalities, and target audience.\n",
      "   - The second document focuses on the DAG-BFT (Directed Acyclic Graph - Byzantine Fault Tolerance) protocols and sequencing in the context of decentralized blockchain systems.\n",
      "   - The third document provides an explanation on how to use Oracles, specifically Pyth data, in EVM contracts on the Movement Network testnet.\n",
      "\n",
      "2. **What is the publication date of the document?**\n",
      "   - The CONTEXT does not provide specific publication dates for any of the documents.\n",
      "\n",
      "3. **Who is the author or organization responsible for the document?**\n",
      "   - The organizations responsible appear to be Movement Labs and possibly Tumi Labs (as referenced in the Movewiffrens document). However, specific author details are not given in the CONTEXT.\n",
      "\n",
      "4. **Where was the document published or distributed?**\n",
      "   - The documents are published or distributed on the respective websites associated with each title:\n",
      "    \n",
      "Explanation: The generated answer does not address the question about the title of the document. Instead, it provides details about the main subject, publication date, authorship, and distribution of the documents, none of which are directly relevant to identifying the title of the document.\n",
      "--------------------------------------------------\n",
      "Original Question: How many chains does the Pyth Network support?\n",
      "Rewritten Question: How many different blockchain networks does the Pyth Network currently support?\n",
      "Answer: The provided context does not specify the number of different blockchain networks currently supported by the Pyth Network. The documents describe various aspects of the Movement SDK, oracles, and how to use Pyth data within the Movement testnet, but do not provide details on the number of blockchain networks Pyth Network supports.\n",
      "\n",
      "Please provide additional information or refer to a specific source detailing the blockchain networks supported by Pyth Network.\n",
      "Explanation: The generated answer does not address the specific question about the number of blockchain networks supported by the Pyth Network. Instead, it mentions the lack of information in the provided context and issues a general request for additional information. This does not contribute any relevant details to answer the original question.\n",
      "--------------------------------------------------\n",
      "Original Question: What is the purpose of Vote-Lock Governance in the Xebra ecosystem?\n",
      "Rewritten Question: - What is Vote-Lock Governance?\n",
      "- How does Vote-Lock Governance function within the Xebra ecosystem?\n",
      "- Why was Vote-Lock Governance implemented in the Xebra ecosystem?\n",
      "- What are the specific goals and objectives of Vote-Lock Governance in the Xebra ecosystem?\n",
      "- What benefits does Vote-Lock Governance offer to the Xebra community?\n",
      "Answer: The provided context does not contain specific details about Vote-Lock Governance or its implementation, goals, objectives, and benefits within the Xebra ecosystem. The documents primarily outline related aspects such as the Dynamic LP Incentive Engine and Hybrid AMM + CLMM.\n",
      "\n",
      "Please provide more information or specific content from the documentation regarding Vote-Lock Governance within the Xebra ecosystem to answer your questions accurately.\n",
      "Explanation: The generated answer does not provide any specific information about the purpose of Vote-Lock Governance in the Xebra ecosystem. Instead, it states that the context does not contain relevant details and requests more information. Therefore, it does not answer the question in any meaningful way.\n",
      "--------------------------------------------------\n",
      "Original Question: What types of auctions are available on WarpGate?\n",
      "Rewritten Question: 1. What different auction formats does WarpGate offer?\n",
      "2. Can you list the specific types of auctions available on WarpGate?\n",
      "3. How many types of auctions can users participate in on WarpGate?\n",
      "4. What are the distinct features of each auction type available on WarpGate?\n",
      "Answer: **1. What different auction formats does WarpGate offer?**\n",
      "**2. Can you list the specific types of auctions available on WarpGate?**\n",
      "**3. How many types of auctions can users participate in on WarpGate?**\n",
      "**4. What are the distinct features of each auction type available on WarpGate?**\n",
      "\n",
      "Based on the provided CONTEXT, WarpGate offers the following different auction formats:\n",
      "- Fixed-Price Auction\n",
      "- Dutch Auction\n",
      "- Playable Auction\n",
      "- Initial Farm Offerings (IFOs)\n",
      "\n",
      "The WarpGate platform provides users the opportunity to participate in four types of auctions: Fixed-Price Auctions, Dutch Auctions, Playable Auctions, and Initial Farm Offerings (IFOs).\n",
      "\n",
      "The distinct features of each auction type are:\n",
      "1. **Fixed-Price Auction**: Participants bid at a set price. The auction operates on a first-come, first-served basis until all tokens are sold.\n",
      "2. **Dutch Auction**: The price of the token decreases over time from an initial high price until all tokens are sold or the minimum price is reached.\n",
      "3. **Playable Auction**: Combines gaming elements with bidding. Participants engage in one-player games, and their allocations are based on their gameplay scores. This\n",
      "Explanation: The generated answer poses multiple reformulations of the original question instead of providing an informative response. It fails to list or describe the types of auctions available on WarpGate, which are Fixed-Price Auction, Dutch Auction, Playable Auction, and Initial Farm Offerings (IFOs), as mentioned in the provided context.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = ['gpt-4o-mini', 'gpt-4o']\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Evaluating with model: {model}\")\n",
    "    \n",
    "    evaluations = evaluate_rag_rewritten(sample, model)\n",
    "    \n",
    "    df_eval = pd.DataFrame(evaluations)\n",
    "    relevance_distribution = df_eval['relevance'].value_counts(normalize=True)\n",
    "    print(f\"Relevance Distribution for {model}:\")\n",
    "    print(relevance_distribution)\n",
    "    \n",
    "    csv_filename = f'rag-eval-results-with-rewriting-{model}.csv'\n",
    "    df_eval.to_csv(csv_filename, index=False)\n",
    "    print(f\"Saved results to {csv_filename}\")\n",
    "    \n",
    "    relevance_counts = df_eval['relevance'].value_counts()\n",
    "    total_evaluations = len(df_eval)\n",
    "    \n",
    "    print(f\"Evaluation Results for {model}:\")\n",
    "    for category in ['RELEVANT', 'PARTLY_RELEVANT', 'NON_RELEVANT']:\n",
    "        count = relevance_counts.get(category, 0)\n",
    "        percentage = (count / total_evaluations) * 100\n",
    "        print(f\"* {count} ({percentage:.1f}%) `{category}`\")\n",
    "    \n",
    "    print(f\"\\nNon-Relevant Answers for {model}:\")\n",
    "    non_relevant = df_eval[df_eval['relevance'] == 'NON_RELEVANT']\n",
    "    for _, row in non_relevant.iterrows():\n",
    "        print(f\"Original Question: {row['original_question']}\")\n",
    "        print(f\"Rewritten Question: {row['rewritten_question']}\")\n",
    "        print(f\"Answer: {row['answer']}\")\n",
    "        print(f\"Explanation: {row['explanation']}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92a7b6-985e-4f64-8589-19a0fb125d06",
   "metadata": {},
   "source": [
    "Query rewritting doesn't seem to help with relevancy. Maybe needs some better prompting, tried 2-3 prompts already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92efa1-0947-4a75-bfab-0b38f1d24587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
